# Web Exploitation Challenge: Inspecting Hidden Website Directories

## Challenge Description
**Title:** The flag is somewhere on this web application, not necessarily on the website.

**Objective:** The challenge hints that the flag is present within the web application but not directly visible on the main website. This suggests that we need to explore other resources related to the site, such as configuration files, hidden directories, or encoded content.

## Understanding Robots.txt
The first step in investigating hidden files and directories on a website is checking for the `robots.txt` file. This file is part of the Robots Exclusion Protocol and is used to provide instructions to web crawlers about which pages or directories should not be indexed. While its intended purpose is to prevent search engines from crawling certain pages, it can sometimes reveal sensitive information about hidden directories.

### Accessing the Robots.txt File
We begin by navigating to the following URL:
```
http://saturn.picoctf.net:56206/robots.txt
```
If the file exists, it may contain directives such as:
```
User-agent: *
Disallow: /cgi-bin/
Disallow: /wp-admin/
Disallow: /hidden-directory/
```
These `Disallow` entries indicate restricted directories that might contain useful information. Our next step is to manually visit these paths in the browser to check if any are accessible.

### Decoding Base64 Strings
While inspecting the `robots.txt` file, we notice an encoded string:
```
ZmxhZzEudHh0
```
This appears to be Base64-encoded data. Decoding it using an online tool or command-line utility like `base64 -d` reveals:
```
flag1.txt
```
This suggests that a file named `flag1.txt` exists somewhere within the serverâ€™s directories.

We found additional encoded strings:
```
anMvbXlmaWxlLnR4dA==
```
Upon decoding, it translates to:
```
js/myfile.txt
```
This strongly indicates that the file containing the flag is located in the `js/` directory.

### Retrieving the Flag
Now that we have identified a possible file path, we can navigate to it in the browser:
```
http://saturn.picoctf.net:56206/js/myfile.txt
```
Upon visiting this URL, we discover the flag:
```
picoCTF{Who_D03sN7_L1k5_90B0T5_718c9043}
```

## Conclusion
This challenge demonstrates the importance of checking `robots.txt` and understanding how it can unintentionally expose sensitive paths. Additionally, we explored Base64 encoding, which is often used to obscure data. By methodically analyzing and decoding hidden information, we successfully retrieved the flag.

### Key Takeaways
- **Check robots.txt:** It may reveal hidden directories.
- **Look for encoded data:** Base64 encoding is a common way to conceal information.
- **Explore hidden files:** Directories listed in `robots.txt` should be manually examined.
- **Web enumeration is crucial:** Understanding how web applications structure their files can help in locating hidden information.

By following these steps, we efficiently uncovered the flag and improved our knowledge of web exploitation techniques.



